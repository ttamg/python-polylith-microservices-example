{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing data\n",
    "\n",
    "Our fake data will be geo data with lat and long.\n",
    "\n",
    "For the purposes of this tutorial we will simulate doing some analysis and generate three outputs from each bundle of data:\n",
    "* The geo centroid (the average lat and long)\n",
    "* The most northerly datapoint\n",
    "\n",
    "We can then return in that in some sort of data structure that would then be written to a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly let's create some fake geo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('53.94313', '10.30215', 'Bad Segeberg', 'DE', 'Europe/Berlin'),\n",
       " ('13.48082', '-86.58208', 'Somoto', 'NI', 'America/Managua'),\n",
       " ('-31.4488', '-60.93173', 'Esperanza', 'AR', 'America/Argentina/Cordoba'),\n",
       " ('33.08014', '-83.2321', 'Milledgeville', 'US', 'America/New_York'),\n",
       " ('30.16688', '-96.39774', 'Brenham', 'US', 'America/Chicago'),\n",
       " ('17.94979', '-94.91386', 'Acayucan', 'MX', 'America/Mexico_City'),\n",
       " ('41.16704', '-73.20483', 'Bridgeport', 'US', 'America/New_York'),\n",
       " ('23.29549', '113.82465', 'Licheng', 'CN', 'Asia/Shanghai')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake = Faker()\n",
    "data = []\n",
    "for i in range(8):\n",
    "    data.append(fake.location_on_land())\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data: list):\n",
    "\n",
    "    # Calculate the average lat and average long from the data\n",
    "    lats = [float(x[0]) for x in data]\n",
    "    average_lat = sum(lats) / len(lats)\n",
    "    longs = [float(x[1]) for x in data]\n",
    "    average_long = sum(longs) / len(longs)\n",
    "\n",
    "    # The most northerly datapoint\n",
    "    most_northerly_lat = max(lats)\n",
    "    most_northerly_index =  lats.index(most_northerly_lat)\n",
    "    most_northerly = data[most_northerly_index]\n",
    "\n",
    "    # Package up into processed data\n",
    "    result = {\n",
    "        \"centroid\": (average_lat, average_long),\n",
    "        \"most_northerly\": most_northerly\n",
    "    }\n",
    "\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'centroid': (22.70431125, -46.3919425),\n",
       " 'most_northerly': ('53.94313',\n",
       "  '10.30215',\n",
       "  'Bad Segeberg',\n",
       "  'DE',\n",
       "  'Europe/Berlin')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_data(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function can mimic our processing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (main, Dec 23 2022, 09:28:24) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e312d00c0035e1a075cca129be038e4a92c47787dd29c5d0f304be6e82a509c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
